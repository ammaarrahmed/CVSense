{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Module 5: Evaluation and Score Analysis\n",
                "\n",
                "This module focuses on evaluating the results from the Similarity & Ranking module. We will:\n",
                "1. Analyze the distribution of similarity scores.\n",
                "2. Visualize the Top-K candidates for each job.\n",
                "3. Perform threshold-based shortlisting analysis.\n",
                "4. Provide a framework for manual validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from IPython.display import display, Image\n",
                "import os\n",
                "\n",
                "# Setting the aesthetic style for plots\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = (12, 6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1. Load Ranking Results\n",
                "We load the CSV generated by Module 4."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ Module 4 results loaded successfully.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Job</th>\n",
                            "      <th>Resume_ID</th>\n",
                            "      <th>Similarity_Score</th>\n",
                            "      <th>Rank</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>jd_ml.txt</td>\n",
                            "      <td>resume_1.txt</td>\n",
                            "      <td>0.3097</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>jd_ml.txt</td>\n",
                            "      <td>resume_3.txt</td>\n",
                            "      <td>0.2349</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>jd_ml.txt</td>\n",
                            "      <td>resume_2.txt</td>\n",
                            "      <td>0.0962</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "         Job     Resume_ID  Similarity_Score  Rank\n",
                            "0  jd_ml.txt  resume_1.txt            0.3097     1\n",
                            "1  jd_ml.txt  resume_3.txt            0.2349     2\n",
                            "2  jd_ml.txt  resume_2.txt            0.0962     3"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "try:\n",
                "    df = pd.read_csv('module5_resume_ranking.csv')\n",
                "    print(\"✅ Module 4 results loaded successfully.\")\n",
                "    display(df.head())\n",
                "except FileNotFoundError:\n",
                "    print(\"❌ Error: 'module5_resume_ranking.csv' not found.\")\n",
                "    data = {\n",
                "        'Job': ['Job_1']*3,\n",
                "        'Rank': [1, 2, 3],\n",
                "        'Resume_ID': ['RES_001', 'RES_002', 'RES_003'],\n",
                "        'Similarity_Score': [0.75, 0.45, 0.30]\n",
                "    }\n",
                "    df = pd.DataFrame(data)\n",
                "    display(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Similarity Score Distribution\n",
                "Understanding how the scores are distributed helps identify if the model is too lenient or too strict."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1000x500 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Code to re-generate figure if needed\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.histplot(df['Similarity_Score'], bins=10, kde=True, color='teal')\n",
                "plt.title('Global Distribution of Similarity Scores')\n",
                "plt.xlabel('Cosine Similarity Score')\n",
                "plt.ylabel('Number of Resumes')\n",
                "plt.axvline(df['Similarity_Score'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"Similarity_Score\"].mean():.2f}')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Top Candidates Analysis\n",
                "Visualizing the top candidates (Top 3) for each job role."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<Figure size 1200x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Code to re-generate figure if needed\n",
                "top_3 = df[df['Rank'] <= 3]\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(data=top_3, x='Similarity_Score', y='Resume_ID', hue='Job')\n",
                "plt.title('Top 3 Candidates per Job Role (by Score)')\n",
                "plt.xlim(0, 1.0)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4. Shortlisting Threshold\n",
                "Define a threshold (e.g., 0.2) to see how many candidates would be automatically shortlisted."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- Shortlist Count per Job ---\n",
                        "Shortlisted  False  True \n",
                        "Job                      \n",
                        "jd_ml.txt        1     2\n"
                    ]
                }
            ],
            "source": [
                "threshold = 0.2\n",
                "df['Shortlisted'] = df['Similarity_Score'] >= threshold\n",
                "\n",
                "shortlist_counts = df.groupby('Job')['Shortlisted'].value_counts().unstack().fillna(0)\n",
                "print(\"--- Shortlist Count per Job ---\")\n",
                "print(shortlist_counts)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5. Manual Validation Export\n",
                "Exporting a subset for manual verification by a recruiter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✅ 'manual_validation_template.csv' created. Please have a recruiter review these rankings.\n"
                    ]
                }
            ],
            "source": [
                "validation_subset = df[df['Rank'] <= 3].copy()\n",
                "validation_subset['Human_Rating (1-5)'] = '' \n",
                "validation_subset['Feedback'] = ''\n",
                "\n",
                "validation_subset.to_csv('manual_validation_template.csv', index=False)\n",
                "print(\"✅ 'manual_validation_template.csv' created. Please have a recruiter review these rankings.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (CVSense)",
            "language": "python",
            "name": "cvsense_env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}